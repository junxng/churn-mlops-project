{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from datetime import datetime\n",
    "pd.options.display.float_format = '{:20.2f}'.format\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import joblib as jb\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', 999)\n",
    "from collections import Counter\n",
    "\n",
    "from typing import NamedTuple\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.metrics import accuracy_score,classification_report,roc_auc_score\n",
    "from imblearn.combine import SMOTEENN\n",
    "from pathlib import Path\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, precision_score, recall_score, f1_score,\n",
    "    classification_report, roc_curve, auc,precision_recall_curve, average_precision_score,matthews_corrcoef\n",
    ")\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import json\n",
    "from google.cloud.storage import Client, transfer_manager\n",
    "import glob\n",
    "from kfp.compiler import Compiler\n",
    "from kfp import dsl\n",
    "from kfp.dsl import (\n",
    "    Input,\n",
    "    Output,\n",
    "    Artifact,\n",
    "    Model,\n",
    "    Metrics,\n",
    "    component\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VersionConfiguration:\n",
    "    def __init__(self):\n",
    "        self.root_folder = \"artifacts\"\n",
    "        self.data_version_dir = os.path.join(self.root_folder, \"data_version\")\n",
    "        self.data_ingestion_dir = os.path.join(self.root_folder, \"data_ingestion\")\n",
    "        self.model_version_dir = os.path.join(self.root_folder, \"model_version\")\n",
    "        self.evaluation_dir = os.path.join(self.root_folder, \"evaluation\")\n",
    "        self.datetime_suffix = datetime.now().strftime('%Y%m%dT%H%M%S')\n",
    "        self.credential = \"C:/Users/Admin/Downloads/llmops-460406-f379299f4261.json\"\n",
    "\n",
    "class gcpConfig:\n",
    "    def __init__(self):\n",
    "        self.credential = \"C:/Users/Admin/Downloads/llmops-460406-f379299f4261.json\"  \n",
    "        self.bucket = \"churn_data_version\"\n",
    "        self.workers = 8\n",
    "class SupportModel:\n",
    "    def most_common(lst):\n",
    "        counts = Counter(lst)\n",
    "        if not counts:\n",
    "            return None \n",
    "        return counts.most_common(1)[0][0]\n",
    "    def get_dummies(df):\n",
    "        categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "        if len(categorical_cols) > 0:\n",
    "            for col in categorical_cols:\n",
    "                if df[col].isin(['yes', 'no', 'True', 'False']).any():\n",
    "                    df[col] = df[col].map({'yes': 1, 'True': 1, 'no': 0, 'False': 0})\n",
    "                else:\n",
    "                    df = pd.get_dummies(df, columns=[col])\n",
    "        return df\n",
    "class ModelConfiguration:\n",
    "    def __init__(self):\n",
    "        self.random_state = 42\n",
    "        self.test_size = 0.2\n",
    "        self.n_estimators = 500\n",
    "        self.criterion=\"entropy\"\n",
    "        self.max_depth=39\n",
    "        self.max_features=\"log2\"\n",
    "        self.min_samples_leaf=2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **DATA PREPROCESS PIPELINE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset():\n",
    "    version_config = VersionConfiguration()\n",
    "    df_input = pd.read_csv(version_config.data_ingestion_dir + \"/input_raw.csv\")\n",
    "    print(f\"Loaded dataset with {len(df_input)} rows\")\n",
    "    print(f\"Columns found: {list(df_input.columns)}\")\n",
    "    input_data_versioned_name = f\"input_raw_data_version_{version_config.datetime_suffix}.csv\"\n",
    "    input_data_versioned_path = Path(version_config.data_version_dir) / input_data_versioned_name\n",
    "    df_input.to_csv(input_data_versioned_path, index=False)\n",
    "    print(f\"Created versioned input data file: {input_data_versioned_path}\")\n",
    "    df_input.columns = df_input.columns.map(lambda x: str(x).strip())\n",
    "    cols_to_drop = {\"Returns\", \"Age\", \"Total Purchase Amount\"}\n",
    "    df_input.drop(columns=[col for col in cols_to_drop if col in df_input.columns], inplace=True)\n",
    "    df_input.dropna(inplace=True)\n",
    "    if 'Price' not in df_input.columns:\n",
    "        df_input['Price'] = df_input['Product Price']\n",
    "    if 'Product Price' not in df_input.columns:\n",
    "        raise KeyError(\"Required column 'Product Price' is missing from the dataset.\")\n",
    "    \n",
    "    df_input['TotalSpent'] = df_input['Quantity'] * df_input['Price']\n",
    "    df_features = df_input.groupby(\"customer_id\", as_index=False, sort=False).agg(\n",
    "        LastPurchaseDate = (\"Purchase Date\",\"max\"),\n",
    "        Favoured_Product_Categories = (\"Product Category\", lambda x: SupportModel.most_common(list(x))),\n",
    "        Frequency = (\"Purchase Date\", \"count\"),\n",
    "        TotalSpent = (\"TotalSpent\", \"sum\"),\n",
    "        Favoured_Payment_Methods = (\"Payment Method\", lambda x: SupportModel.most_common(list(x))),\n",
    "        Customer_Name = (\"Customer Name\", \"first\"),\n",
    "        Customer_Label = (\"Customer_Labels\", \"first\"),\n",
    "        Churn = (\"Churn\", \"first\"),\n",
    "    )\n",
    "\n",
    "    df_features = df_features.drop_duplicates(subset=['Customer_Name'], keep='first')\n",
    "    df_features['LastPurchaseDate'] = pd.to_datetime(df_features['LastPurchaseDate'])\n",
    "    df_features['LastPurchaseDate'] = df_features['LastPurchaseDate'].dt.date\n",
    "    df_features['LastPurchaseDate'] = pd.to_datetime(df_features['LastPurchaseDate'])\n",
    "    max_LastBuyingDate = df_features[\"LastPurchaseDate\"].max()\n",
    "    df_features['Recency'] = (max_LastBuyingDate - df_features['LastPurchaseDate']).dt.days\n",
    "    df_features['LastPurchaseDate'] = df_features['LastPurchaseDate'].dt.date\n",
    "    df_features['Avg_Spend_Per_Purchase'] = df_features['TotalSpent'] / df_features['Frequency'].replace(0, 1)\n",
    "    df_features['Purchase_Consistency'] = df_features['Recency'] / df_features['Frequency'].replace(0, 1)\n",
    "    df_features.drop(columns=[\"customer_id\",\"LastPurchaseDate\",'Customer_Name'], inplace=True)\n",
    "    print(f\"processed dataset with {len(df_features)} rows\")\n",
    "    print(f\"After feature engineering columns: {list(df_features.columns)}\")\n",
    "    print(f\"Data shape after feature engineering: {df_features.shape}\")\n",
    "    print(f\"First few rows of feature engineered data: \\n{df_features.head()}\")\n",
    "    model_data_versioned_name = f\"model_data_version_{version_config.datetime_suffix}.csv\"\n",
    "    model_data_versioned_path = Path(version_config.data_version_dir) / model_data_versioned_name\n",
    "    df_features.to_csv(model_data_versioned_path, index=False)\n",
    "    print(f\"Created versioned model data file: {model_data_versioned_path}\")\n",
    "    df_encode = SupportModel.get_dummies(df_features)\n",
    "    print(\"Successfully processed data\")\n",
    "    return df_encode\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **SPLIT DATA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(df):\n",
    "    version_config = VersionConfiguration()\n",
    "    df_model = df.copy()\n",
    "    X = df_model.drop('Churn',axis=1)\n",
    "    y = df_model['Churn']\n",
    "    print(f\"X shape (features): {X.shape}\")\n",
    "    print(f\"y shape (target): {y.shape}\")\n",
    "\n",
    "    print(f\"Target variable shape: {y.shape}\")\n",
    "    print(f\"NaN count in target: {y.isna().sum()}\")\n",
    "    print(f\"Target variable distribution: \\n{y.value_counts(normalize=True)}\")\n",
    "\n",
    "    if y.isna().sum() > 0:\n",
    "        print(f\"Found {y.isna().sum()} NaN values in target variable, filling with 0\")\n",
    "        y = y.fillna(0)\n",
    "\n",
    "    nan_cols = X.columns[X.isna().any()].tolist()\n",
    "    if nan_cols:\n",
    "        print(f\"Found NaN values in feature columns: {nan_cols}\")\n",
    "        X = X.fillna(0)\n",
    "\n",
    "    print(f\"Final feature matrix shape: {X.shape}\")\n",
    "    print(f\"Final target vector shape: {y.shape}\")\n",
    "\n",
    "    class_distribution = y.value_counts(normalize=True)\n",
    "    print(f\"Target variable distribution (normalized): \\n{class_distribution}\")\n",
    "\n",
    "    imbalance_threshold = 0.4\n",
    "\n",
    "    if class_distribution.min() < imbalance_threshold:\n",
    "        print(\"Target variable is imbalanced. Applying SMOTEENN...\")\n",
    "        smote = SMOTEENN(random_state=42)\n",
    "        X_res, y_res = smote.fit_resample(X, y)\n",
    "        print(f\"Resampled feature matrix shape: {X_res.shape}\")\n",
    "        print(f\"Resampled target distribution: \\n{y_res.value_counts()}\")\n",
    "    else:\n",
    "        print(\"Target variable is balanced. Skipping SMOTEENN.\")\n",
    "        X_res, y_res = X, y\n",
    "    \n",
    "    print(\"Splitting data into train and test sets\")\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.2, random_state=42)\n",
    "    print(f\"Train data: {X_train.shape}, Test data: {X_test.shape}\")\n",
    "    \n",
    "    print(\"Converting variables to DataFrames...\")\n",
    "    \n",
    "    if not isinstance(X_train, pd.DataFrame):\n",
    "        if hasattr(X_res, 'columns'):\n",
    "            X_train = pd.DataFrame(X_train, columns=X_res.columns)\n",
    "        else:\n",
    "            X_train = pd.DataFrame(X_train, columns=X.columns)\n",
    "    \n",
    "    if not isinstance(X_test, pd.DataFrame):\n",
    "        if hasattr(X_res, 'columns'):\n",
    "            X_test = pd.DataFrame(X_test, columns=X_res.columns)\n",
    "        else:\n",
    "            X_test = pd.DataFrame(X_test, columns=X.columns)\n",
    "    \n",
    "    if not isinstance(y_train, pd.DataFrame):\n",
    "        y_train = pd.DataFrame(y_train, columns=['Churn'])\n",
    "    \n",
    "    if not isinstance(y_test, pd.DataFrame):\n",
    "        y_test = pd.DataFrame(y_test, columns=['Churn'])\n",
    "    \n",
    "    print(f\"Final DataFrame shapes:\")\n",
    "    print(f\"X_train: {X_train.shape}, type: {type(X_train)}\")\n",
    "    print(f\"X_test: {X_test.shape}, type: {type(X_test)}\")\n",
    "    print(f\"y_train: {y_train.shape}, type: {type(y_train)}\")\n",
    "    print(f\"y_test: {y_test.shape}, type: {type(y_test)}\")\n",
    "    \n",
    "    train_feature_path = os.path.join(version_config.data_version_dir, f\"train_feature_version_{version_config.datetime_suffix}.csv\")\n",
    "    test_feature_path = os.path.join(version_config.data_version_dir, f\"test_feature_version_{version_config.datetime_suffix}.csv\")\n",
    "    train_target_path = os.path.join(version_config.data_version_dir, f\"train_target_version_{version_config.datetime_suffix}.csv\")\n",
    "    test_target_path = os.path.join(version_config.data_version_dir, f\"test_target_version_{version_config.datetime_suffix}.csv\")\n",
    "    \n",
    "    X_train.to_csv(train_feature_path, index=False)\n",
    "    X_test.to_csv(test_feature_path, index=False)\n",
    "    y_train.to_csv(train_target_path, index=False)\n",
    "    y_test.to_csv(test_target_path, index=False)\n",
    "    \n",
    "    print(\"Data successfully saved to CSV files\")\n",
    "    \n",
    "    return train_feature_path, test_feature_path, train_target_path, test_target_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **PREPARE ESSENTIALS FOR MODEL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_base_model(X_train_path, X_test_path):\n",
    "    model_config = ModelConfiguration()\n",
    "    version_config = VersionConfiguration()\n",
    "    model = RandomForestClassifier(\n",
    "    n_estimators=model_config.n_estimators, \n",
    "    random_state=model_config.random_state,\n",
    "    criterion=model_config.criterion,\n",
    "    max_depth=model_config.max_depth,\n",
    "    max_features=model_config.max_features,\n",
    "    min_samples_leaf=model_config.min_samples_leaf\n",
    ")\n",
    "    base_model_version_name = f\"base_model_version_{version_config.datetime_suffix}.pkl\"\n",
    "    base_model_version_path = Path(version_config.model_version_dir) / base_model_version_name\n",
    "    jb.dump(model, base_model_version_path)\n",
    "    print(\"Created versioned base model file:\", base_model_version_path)\n",
    "    X_train = pd.read_csv(X_train_path)\n",
    "    X_test = pd.read_csv(X_test_path)\n",
    "\n",
    "    scaled_test_data_path = os.path.join(version_config.data_version_dir, f\"test_feature_scaled_version_{version_config.datetime_suffix}.csv\")\n",
    "    scaled_train_data_path = os.path.join(version_config.data_version_dir, f\"train_feature_scaled_version_{version_config.datetime_suffix}.csv\")\n",
    "    scaler_path = os.path.join(version_config.model_version_dir, f\"scaler_churn_version_{version_config.datetime_suffix}.pkl\")\n",
    "    scaler = RobustScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    jb.dump(scaler, scaler_path)\n",
    "    \n",
    "    X_train_scaled_df = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
    "    X_test_scaled_df = pd.DataFrame(X_test_scaled, columns=X_test.columns)\n",
    "\n",
    "    X_train_scaled_df.to_csv(scaled_train_data_path, index=False)\n",
    "    X_test_scaled_df.to_csv(scaled_test_data_path, index=False)\n",
    "    \n",
    "    print(f\"Scalers and scaled data saved:\")\n",
    "    print(f\"  Scaler: {scaler_path}\")\n",
    "    print(f\"  X_train_scaled: {scaled_train_data_path}\")\n",
    "    print(f\"  X_test_scaled: {scaled_test_data_path}\")\n",
    "    return base_model_version_path, scaled_test_data_path, scaled_train_data_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **TRAINNING PIPELINE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainning(base_model_path, scaled_train_path, scaled_test_path, y_train_path, y_test_path):\n",
    "    version_config = VersionConfiguration()\n",
    "    model = jb.load(base_model_path)\n",
    "    X_train_scaled = pd.read_csv(scaled_train_path)\n",
    "    X_test_scaled = pd.read_csv(scaled_test_path)\n",
    "    y_train = pd.read_csv(y_train_path)\n",
    "    y_test = pd.read_csv(y_test_path)\n",
    "    \n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    prediction = model.predict(X_test_scaled)\n",
    "    accuracy = accuracy_score(y_test, prediction)\n",
    "    print(f\"Initial model accuracy: {accuracy:.4f}\")\n",
    "    \n",
    "    if accuracy < 0.85:\n",
    "        print(\"Trigger fine-tuning!\")\n",
    "        rf_params = {\n",
    "            'n_estimators': [100, 200, 300, 400, 500, 700, 1000],  \n",
    "            'criterion': ['gini', 'entropy', 'log_loss'],          \n",
    "            'max_depth': [None, 10, 20, 30, 50, 70],                \n",
    "            'min_samples_split': [2, 5, 10, 15],                    \n",
    "            'min_samples_leaf': [1, 2, 4, 6],                       \n",
    "            'max_features': ['sqrt', 'log2', None],                \n",
    "            'bootstrap': [True, False],                             \n",
    "            'class_weight': [None, 'balanced', 'balanced_subsample']  \n",
    "        }\n",
    "        random_search = RandomizedSearchCV(model, rf_params, cv=5, n_jobs=1, n_iter=20, random_state=42, scoring='accuracy')\n",
    "        random_search.fit(X_train_scaled, y_train)\n",
    "        best_model = RandomForestClassifier(**random_search.best_params_, random_state=42)\n",
    "        best_model.fit(X_train_scaled, y_train)  # Train the best model\n",
    "        print(f\"Best parameters found: {random_search.best_params_}\")\n",
    "        print(f\"Best cross-validation score: {random_search.best_score_:.4f}\")\n",
    "        \n",
    "        best_prediction = best_model.predict(X_test_scaled)\n",
    "        best_accuracy = accuracy_score(y_test, best_prediction)\n",
    "        print(f\"Best model accuracy on test set: {best_accuracy:.4f}\")\n",
    "        \n",
    "        best_model_version_name = f\"fine_tuned_model_version_{version_config.datetime_suffix}.pkl\"\n",
    "        best_model_version_path = Path(version_config.model_version_dir) / best_model_version_name\n",
    "        jb.dump(best_model, best_model_version_path)\n",
    "        print(f\"Best model saved to: {best_model_version_path}\")\n",
    "    else:\n",
    "        print(\"No fine-tuning needed!\")\n",
    "        best_model = model\n",
    "\n",
    "    return best_model, X_test_scaled, y_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **EVALUATING PIPELINE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluating(model, X_test_scaled, y_test):\n",
    "    version_config = VersionConfiguration()\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    y_pred_prob = model.predict_proba(X_test_scaled)[:, 1]\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_prob)\n",
    "    mcc = matthews_corrcoef(y_test, y_pred)\n",
    "    avg_precision = average_precision_score(y_test, y_pred_prob)\n",
    "    metrics = {\n",
    "    \"precision\": float(precision),\n",
    "    \"recall\": float(recall),\n",
    "    \"f1_score\": float(f1),\n",
    "    \"roc_auc\": float(roc_auc),\n",
    "    \"mcc\": float(mcc),\n",
    "    \"avg_precision\": float(avg_precision)\n",
    "}\n",
    "        \n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    metrics[\"classification_report\"] = report\n",
    "    \n",
    "    metrics_file_versioned = Path(version_config.evaluation_dir) / f\"metrics_{version_config.datetime_suffix}.json\"\n",
    "    with open(metrics_file_versioned, \"w\") as f:\n",
    "        json.dump(metrics, f)\n",
    "    print(f\"Metrics saved to: {metrics_file_versioned}\")\n",
    "    \n",
    "    precision_vals, recall_vals, _ = precision_recall_curve(y_test, y_pred_prob)\n",
    "    avg_precision = average_precision_score(y_test, y_pred_prob)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(recall_vals, precision_vals, color='purple', lw=2,\n",
    "            label=f'Precision-Recall curve (AP = {avg_precision:.3f})')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title('Precision-Recall Curve')\n",
    "    plt.legend(loc='lower left')\n",
    "\n",
    "    pr_path = os.path.join(version_config.evaluation_dir, f\"precision_recall_curve_{version_config.datetime_suffix}.png\")\n",
    "    plt.savefig(pr_path)\n",
    "    plt.close()\n",
    "    print(f\"Precision-Recall curve saved to: {pr_path}\")\n",
    "    print(\"Creating ROC curve plot\")\n",
    "    \n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (AUC = {roc_auc:.3f})')\n",
    "    plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    \n",
    "    # Save the plot with datetime naming\n",
    "    roc_path = os.path.join(version_config.evaluation_dir, f\"roc_curve_{version_config.datetime_suffix}.png\")\n",
    "    plt.savefig(roc_path)\n",
    "    plt.close()\n",
    "    print(f\"ROC curve saved to: {roc_path}\")\n",
    "    return pr_path, roc_path, metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **PUSHING STORAGE PIPELINE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_to_GCP(filenames=None):\n",
    "    \"\"\"Upload multiple files to Google Cloud Storage with proper error handling.\"\"\"\n",
    "    try:\n",
    "        version_config = VersionConfiguration()\n",
    "        gcp_config = gcpConfig()\n",
    "        bucket_name = gcp_config.bucket\n",
    "        workers = gcp_config.workers\n",
    "\n",
    "        os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = gcp_config.credential\n",
    "        \n",
    "        files_to_upload = []\n",
    "        \n",
    "        if filenames:\n",
    "            if isinstance(filenames, (Path, str)):\n",
    "                filenames = [str(filenames)]\n",
    "            else:\n",
    "                filenames = [str(f) for f in filenames]\n",
    "            \n",
    "            for filename in filenames:\n",
    "                for source_dir in [version_config.data_version_dir, version_config.evaluation_dir]:\n",
    "                    file_path = os.path.join(source_dir, filename)\n",
    "                    if os.path.exists(file_path):\n",
    "                        files_to_upload.append((filename, source_dir))\n",
    "                        break\n",
    "                else:\n",
    "                    print(f\"File does not exist in any source directory: {filename}\")\n",
    "        else:\n",
    "            # Upload all files from both directories\n",
    "            target_dirs = [\n",
    "                version_config.data_version_dir,\n",
    "                version_config.evaluation_dir\n",
    "            ]\n",
    "            \n",
    "            for source_dir in target_dirs:\n",
    "                if os.path.exists(source_dir):\n",
    "                    print(f\"Scanning directory: {source_dir}\")\n",
    "                    data_files = glob.glob(os.path.join(source_dir, \"**\", \"*\"), recursive=True)\n",
    "                    for file_path in data_files:\n",
    "                        if os.path.isfile(file_path):\n",
    "                            rel_path = os.path.relpath(file_path, source_dir)\n",
    "                            files_to_upload.append((rel_path, source_dir))\n",
    "                else:\n",
    "                    print(f\"Directory does not exist: {source_dir}\")\n",
    "        \n",
    "        if not files_to_upload:\n",
    "            print(\"No files found to upload\")\n",
    "            return 0, 0\n",
    "        \n",
    "        print(f\"Found {len(files_to_upload)} files to upload\")\n",
    "        \n",
    "        # Initialize storage client and bucket\n",
    "        storage_client = Client()\n",
    "        bucket = storage_client.bucket(bucket_name)\n",
    "\n",
    "        # Group files by source directory for batch upload\n",
    "        uploads_by_source = {}\n",
    "        for rel_path, source_dir in files_to_upload:\n",
    "            if source_dir not in uploads_by_source:\n",
    "                uploads_by_source[source_dir] = []\n",
    "            uploads_by_source[source_dir].append(rel_path)\n",
    "\n",
    "        total_success = 0\n",
    "        total_errors = 0\n",
    "\n",
    "        for source_dir, file_list in uploads_by_source.items():\n",
    "            print(f\"Uploading {len(file_list)} files from {source_dir}\")\n",
    "            \n",
    "            try:\n",
    "                results = transfer_manager.upload_many_from_filenames(\n",
    "                    bucket, \n",
    "                    file_list, \n",
    "                    source_directory=source_dir,\n",
    "                    max_workers=workers, \n",
    "                    blob_name_prefix=\"churn_data_store/\"\n",
    "                )\n",
    "\n",
    "                success_count = 0\n",
    "                error_count = 0\n",
    "                \n",
    "                for name, result in zip(file_list, results):\n",
    "                    if isinstance(result, Exception):\n",
    "                        print(f\"Failed to upload {name}: {result}\")\n",
    "                        error_count += 1\n",
    "                    else:\n",
    "                        print(f\"Uploaded {name} to bucket {bucket.name}\")\n",
    "                        success_count += 1\n",
    "                \n",
    "                total_success += success_count\n",
    "                total_errors += error_count\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Failed to upload batch from {source_dir}: {e}\")\n",
    "                total_errors += len(file_list)\n",
    "        \n",
    "        print(f\"Upload completed: {total_success} successful, {total_errors} failed\")\n",
    "        return total_success, total_errors\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"Cloud storage upload failed: {e}\")\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **CLEANUP PIPELINE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup_temp_files():\n",
    "    \"\"\"Clean up temporary versioned files after pipeline completion.\"\"\"\n",
    "\n",
    "    version_config = VersionConfiguration()\n",
    "    data_version_dir = version_config.data_version_dir\n",
    "    evaluation_dir = version_config.evaluation_dir\n",
    "    try:\n",
    "        # Pattern: *_version_YYYYMMDDTHHMMSS.csv\n",
    "        data_version_files = glob.glob(os.path.join(data_version_dir, \"*_version_????????T??????.csv\"))\n",
    "        print(f\"Found {len(data_version_files)} timestamp-versioned data files to clean\")\n",
    "        \n",
    "        for file_path in data_version_files:\n",
    "            try:\n",
    "                os.remove(file_path)\n",
    "                print(f\"Deleted temporary file: {os.path.basename(file_path)}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to delete file {file_path}: {e}\")\n",
    "        \n",
    "        # Pattern: *_YYYYMMDDTHHMMSS.json and *_YYYYMMDDTHHMMSS.png\n",
    "        eval_json_files = glob.glob(os.path.join(evaluation_dir, \"*_????????T??????.json\"))\n",
    "        eval_png_files = glob.glob(os.path.join(evaluation_dir, \"*_????????T??????.png\"))\n",
    "        eval_files = eval_json_files + eval_png_files\n",
    "        print(f\"Found {len(eval_files)} timestamp-versioned evaluation files to clean\")\n",
    "        \n",
    "        for file_path in eval_files:\n",
    "            try:\n",
    "                os.remove(file_path)\n",
    "                print(f\"Deleted temporary file: {os.path.basename(file_path)}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to delete file {file_path}: {e}\")\n",
    "        \n",
    "        remaining_data_files = len(glob.glob(os.path.join(data_version_dir, \"*.csv\")))\n",
    "        remaining_eval_files = len(glob.glob(os.path.join(evaluation_dir, \"*\")))\n",
    "        print(f\"Kept {remaining_data_files} essential data files for DVC tracking\")\n",
    "        print(f\"Kept {remaining_eval_files} essential evaluation files for DVC tracking\")\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"Error during cleanup: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try:\n",
    "#     print(f\">>>>>> Pipeline Started <<<<<<\")\n",
    "#     df_encode = get_dataset()\n",
    "#     print(f\">>>>>> stage Data Ingestion Stage completed <<<<<<\\n\\nx==========x\")\n",
    "#     train_feature_path, test_feature_path, train_target_path, test_target_path = split_data(df_encode)\n",
    "#     print(f\">>>>>> stage Data Split Stage completed <<<<<<\\n\\nx==========x\")\n",
    "#     base_model_version_path, scaled_test_data_path, scaled_train_data_path = prepare_base_model(train_feature_path, test_feature_path)\n",
    "#     print(f\">>>>>> stage Prepare Base Model Stage completed <<<<<<\\n\\nx==========x\")\n",
    "#     best_model, X_test_scaled, y_test = trainning(base_model_path=base_model_version_path, scaled_train_path=scaled_train_data_path, scaled_test_path=scaled_test_data_path, y_train_path=train_target_path, y_test_path=test_target_path)\n",
    "#     print(f\">>>>>> stage Model Training Stage completed <<<<<<\\n\\nx==========x\")\n",
    "#     pr_path, roc_path, metrics = evaluating(best_model, X_test_scaled, y_test)\n",
    "#     print(f\">>>>>> stage Model Evaluation Stage completed <<<<<<\\n\\nx==========x\")\n",
    "#     upload_to_GCP()\n",
    "#     print(f\">>>>>> stage Cloud Storage Upload Stage completed <<<<<<\\n\\nx==========x\")\n",
    "#     cleanup_temp_files()\n",
    "#     print(f\">>>>>> Pipeline Completed <<<<<<\")\n",
    "# except Exception as e:\n",
    "#     print(e)\n",
    "#     raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **KUBEFLOW PIPELINE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kfp import dsl\n",
    "from kfp.dsl import Input, Output, Model, Dataset, Metrics, Artifact\n",
    "from kfp import compiler\n",
    "from kfp.client import Client\n",
    "from typing import NamedTuple\n",
    "import os\n",
    "import time\n",
    "\n",
    "@dsl.pipeline(\n",
    "    name='churn-prediction-pipeline-gcs',\n",
    "    description='A pipeline for churn prediction with GCS data source'\n",
    ")\n",
    "def churn_prediction_pipeline():\n",
    "\n",
    "    @dsl.component(\n",
    "        base_image='python:3.11.9',\n",
    "        packages_to_install=[\n",
    "            'pandas==2.0.3',\n",
    "            'numpy==1.24.3',\n",
    "            'scikit-learn==1.3.0',\n",
    "            'imbalanced-learn==0.11.0',\n",
    "            'joblib==1.3.2',\n",
    "            'matplotlib==3.7.2',\n",
    "        ]\n",
    "        \n",
    "    )\n",
    "    def data_ingestion(processed_data: Output[Dataset]):\n",
    "        import pandas as pd\n",
    "        import os\n",
    "        from datetime import datetime\n",
    "        from pathlib import Path\n",
    "        from collections import Counter\n",
    "\n",
    "        class VersionConfiguration:\n",
    "            def __init__(self):\n",
    "                self.root_folder = \"/tmp/artifacts\"\n",
    "                self.data_version_dir = os.path.join(self.root_folder, \"data_version\")\n",
    "                os.makedirs(self.data_version_dir, exist_ok=True)\n",
    "                self.datetime_suffix = datetime.now().strftime('%Y%m%dT%H%M%S')\n",
    "\n",
    "\n",
    "\n",
    "        class SupportModel:\n",
    "            @staticmethod\n",
    "            def most_common(lst):\n",
    "                counts = Counter(lst)\n",
    "                if not counts:\n",
    "                    return None \n",
    "                return counts.most_common(1)[0][0]\n",
    "            \n",
    "            @staticmethod\n",
    "            def get_dummies(df):\n",
    "                categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "                if len(categorical_cols) > 0:\n",
    "                    for col in categorical_cols:\n",
    "                        if df[col].isin(['yes', 'no', 'True', 'False']).any():\n",
    "                            df[col] = df[col].map({'yes': 1, 'True': 1, 'no': 0, 'False': 0})\n",
    "                        else:\n",
    "                            df = pd.get_dummies(df, columns=[col], prefix=col)\n",
    "                return df\n",
    "\n",
    "        def get_dataset():\n",
    "            version_config = VersionConfiguration()\n",
    "\n",
    "            try:\n",
    "\n",
    "                df_input = pd.read_csv(\"https://raw.githubusercontent.com/Teungtran/churn_mlops/main/artifacts/data_ingestion/input_raw.csv\")\n",
    "                print(f\"Loaded dataset with {len(df_input)} rows and columns {list(df_input.columns)}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading data from github: {str(e)}\")\n",
    "                raise\n",
    "            \n",
    "            if df_input is None or df_input.empty:\n",
    "                raise ValueError(\"Failed to load data from github or data is empty\")\n",
    "            \n",
    "            input_data_versioned_name = f\"input_raw_data_version_{version_config.datetime_suffix}.csv\"\n",
    "            input_data_versioned_path = Path(version_config.data_version_dir) / input_data_versioned_name\n",
    "            df_input.to_csv(input_data_versioned_path, index=False)\n",
    "            print(f\"Created versioned input data file: {input_data_versioned_path}\")\n",
    "            \n",
    "            df_input.columns = df_input.columns.map(lambda x: str(x).strip())\n",
    "            \n",
    "            cols_to_drop = {\"Returns\", \"Age\", \"Total Purchase Amount\"}\n",
    "            df_input.drop(columns=[col for col in cols_to_drop if col in df_input.columns], inplace=True)\n",
    "            df_input.dropna(inplace=True)\n",
    "            \n",
    "            if 'Price' not in df_input.columns and 'Product Price' in df_input.columns:\n",
    "                df_input['Price'] = df_input['Product Price']\n",
    "            \n",
    "            required_columns = ['customer_id', 'Purchase Date', 'Product Category', 'Quantity', 'Price', 'Payment Method', 'Customer Name', 'Customer_Labels', 'Churn']\n",
    "            missing_columns = [col for col in required_columns if col not in df_input.columns]\n",
    "            \n",
    "            if missing_columns:\n",
    "                print(f\"Warning: Missing required columns: {missing_columns}\")\n",
    "                print(f\"Available columns: {list(df_input.columns)}\")\n",
    "                \n",
    "                # Try to map common column variations\n",
    "                column_mappings = {\n",
    "                    'customer_id': ['Customer ID', 'CustomerId', 'ID'],\n",
    "                    'Purchase Date': ['PurchaseDate', 'Date', 'purchase_date'],\n",
    "                    'Product Category': ['ProductCategory', 'Category', 'product_category'],\n",
    "                    'Customer Name': ['CustomerName', 'Name', 'customer_name'],\n",
    "                    'Customer_Labels': ['CustomerLabels', 'Labels', 'customer_labels'],\n",
    "                    'Payment Method': ['PaymentMethod', 'payment_method']\n",
    "                }\n",
    "                \n",
    "                for standard_col, alternatives in column_mappings.items():\n",
    "                    if standard_col not in df_input.columns:\n",
    "                        for alt in alternatives:\n",
    "                            if alt in df_input.columns:\n",
    "                                df_input[standard_col] = df_input[alt]\n",
    "                                print(f\"Mapped {alt} -> {standard_col}\")\n",
    "                                break\n",
    "            \n",
    "            if all(col in df_input.columns for col in ['Quantity', 'Price']):\n",
    "                df_input['TotalSpent'] = df_input['Quantity'] * df_input['Price']\n",
    "                \n",
    "                df_features = df_input.groupby(\"customer_id\", as_index=False, sort=False).agg(\n",
    "                    LastPurchaseDate=(\"Purchase Date\", \"max\"),\n",
    "                    Favoured_Product_Categories=(\"Product Category\", lambda x: SupportModel.most_common(list(x))),\n",
    "                    Frequency=(\"Purchase Date\", \"count\"),\n",
    "                    TotalSpent=(\"TotalSpent\", \"sum\"),\n",
    "                    Favoured_Payment_Methods=(\"Payment Method\", lambda x: SupportModel.most_common(list(x))),\n",
    "                    Customer_Name=(\"Customer Name\", \"first\"),\n",
    "                    Customer_Label=(\"Customer_Labels\", \"first\"),\n",
    "                    Churn=(\"Churn\", \"first\"),\n",
    "                )\n",
    "\n",
    "                df_features = df_features.drop_duplicates(subset=['Customer_Name'], keep='first')\n",
    "                df_features['LastPurchaseDate'] = pd.to_datetime(df_features['LastPurchaseDate'])\n",
    "                max_LastBuyingDate = df_features[\"LastPurchaseDate\"].max()\n",
    "                df_features['Recency'] = (max_LastBuyingDate - df_features['LastPurchaseDate']).dt.days\n",
    "                df_features['Avg_Spend_Per_Purchase'] = df_features['TotalSpent'] / df_features['Frequency'].replace(0, 1)\n",
    "                df_features['Purchase_Consistency'] = df_features['Recency'] / df_features['Frequency'].replace(0, 1)\n",
    "                \n",
    "                # Drop unnecessary columns\n",
    "                df_features.drop(columns=[\"customer_id\", \"LastPurchaseDate\", 'Customer_Name'], inplace=True)\n",
    "                df_features.dropna(inplace=True)\n",
    "                \n",
    "                print(f\"Processed dataset with {len(df_features)} rows\")\n",
    "                print(f\"After feature engineering columns: {list(df_features.columns)}\")\n",
    "                \n",
    "                # Encode categorical variables\n",
    "                df_encode = SupportModel.get_dummies(df_features)\n",
    "            else:\n",
    "                print(\"Warning: Required columns for feature engineering not found. Using original data.\")\n",
    "                df_encode = SupportModel.get_dummies(df_input)\n",
    "            \n",
    "            # Save processed data\n",
    "            df_encode.to_csv(processed_data.path, index=False)\n",
    "            print(f\"Processed data saved to: {processed_data.path}\")\n",
    "            print(f\"Final dataset shape: {df_encode.shape}\")\n",
    "            print(f\"Final columns: {list(df_encode.columns)}\")\n",
    "            \n",
    "            return df_encode\n",
    "\n",
    "        get_dataset()\n",
    "\n",
    "    @dsl.component(\n",
    "        base_image='python:3.11.9',\n",
    "        packages_to_install=[\n",
    "            'pandas==2.0.3',\n",
    "            'numpy==1.24.3',\n",
    "            'scikit-learn==1.3.0',\n",
    "            'imbalanced-learn==0.11.0'\n",
    "        ]\n",
    "    )\n",
    "    def data_split(\n",
    "        processed_data: Input[Dataset],\n",
    "        X_train: Output[Dataset],\n",
    "        X_test: Output[Dataset],\n",
    "        y_train: Output[Dataset],\n",
    "        y_test: Output[Dataset]\n",
    "    ):\n",
    "        import pandas as pd\n",
    "        from sklearn.model_selection import train_test_split\n",
    "        from imblearn.combine import SMOTEENN\n",
    "        from collections import Counter\n",
    "\n",
    "        def split_data():\n",
    "            # Load processed data\n",
    "            df_model = pd.read_csv(processed_data.path)\n",
    "            print(f\"Loaded data with shape: {df_model.shape}\")\n",
    "            print(f\"Columns: {list(df_model.columns)}\")\n",
    "            \n",
    "            # Check if Churn column exists\n",
    "            if 'Churn' not in df_model.columns:\n",
    "                print(\"Warning: 'Churn' column not found. Available columns:\")\n",
    "                print(list(df_model.columns))\n",
    "                potential_targets = [col for col in df_model.columns if 'churn' in col.lower() or 'target' in col.lower()]\n",
    "                if potential_targets:\n",
    "                    target_col = potential_targets[0]\n",
    "                    print(f\"Using '{target_col}' as target column\")\n",
    "                    df_model['Churn'] = df_model[target_col]\n",
    "                else:\n",
    "                    raise ValueError(\"No suitable target column found\")\n",
    "            \n",
    "            # Separate features and target\n",
    "            X = df_model.drop('Churn', axis=1)\n",
    "            y = df_model['Churn']\n",
    "            \n",
    "            print(f\"X shape (features): {X.shape}\")\n",
    "            print(f\"y shape (target): {y.shape}\")\n",
    "            print(f\"Target distribution: \\n{y.value_counts(normalize=True)}\")\n",
    "\n",
    "            # Handle missing values\n",
    "            if y.isna().sum() > 0:\n",
    "                print(f\"Found {y.isna().sum()} NaN values in target variable, filling with 0\")\n",
    "                y = y.fillna(0)\n",
    "\n",
    "            if X.isna().any().any():\n",
    "                print(\"Found NaN values in features, filling with 0\")\n",
    "                X = X.fillna(0)\n",
    "\n",
    "            # Check for class imbalance\n",
    "            class_distribution = y.value_counts(normalize=True)\n",
    "            imbalance_threshold = 0.4\n",
    "\n",
    "            if len(class_distribution) > 1 and class_distribution.min() < imbalance_threshold:\n",
    "                print(\"Target variable is imbalanced. Applying SMOTEENN...\")\n",
    "                try:\n",
    "                    smote = SMOTEENN(random_state=42)\n",
    "                    X_res, y_res = smote.fit_resample(X, y)\n",
    "                    print(f\"Resampled feature matrix shape: {X_res.shape}\")\n",
    "                    print(f\"Resampled target distribution: \\n{Counter(y_res)}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"SMOTEENN failed: {e}. Using original data.\")\n",
    "                    X_res, y_res = X, y\n",
    "            else:\n",
    "                print(\"Target variable is balanced or single class. Skipping SMOTEENN.\")\n",
    "                X_res, y_res = X, y\n",
    "            \n",
    "            # Split data\n",
    "            X_train_data, X_test_data, y_train_data, y_test_data = train_test_split(\n",
    "                X_res, y_res, test_size=0.2, random_state=42, \n",
    "                stratify=y_res if len(Counter(y_res)) > 1 else None\n",
    "            )\n",
    "            \n",
    "            print(f\"Train data: {X_train_data.shape}, Test data: {X_test_data.shape}\")\n",
    "            \n",
    "            # Convert to DataFrames if needed\n",
    "            if hasattr(X_res, 'columns'):\n",
    "                columns = X_res.columns\n",
    "            else:\n",
    "                columns = X.columns\n",
    "                \n",
    "            X_train_df = pd.DataFrame(X_train_data, columns=columns)\n",
    "            X_test_df = pd.DataFrame(X_test_data, columns=columns)\n",
    "            y_train_df = pd.DataFrame(y_train_data, columns=['Churn'])\n",
    "            y_test_df = pd.DataFrame(y_test_data, columns=['Churn'])\n",
    "            \n",
    "            # Save split data\n",
    "            X_train_df.to_csv(X_train.path, index=False)\n",
    "            X_test_df.to_csv(X_test.path, index=False)\n",
    "            y_train_df.to_csv(y_train.path, index=False)\n",
    "            y_test_df.to_csv(y_test.path, index=False)\n",
    "            \n",
    "            print(\"Data split completed and saved\")\n",
    "\n",
    "        split_data()\n",
    "\n",
    "    @dsl.component(\n",
    "        base_image='python:3.11.9',\n",
    "        packages_to_install=[\n",
    "            'pandas==2.0.3',\n",
    "            'numpy==1.24.3',\n",
    "            'scikit-learn==1.3.0',\n",
    "            'joblib==1.3.2'\n",
    "        ]\n",
    "    )\n",
    "    def prepare_model(\n",
    "        X_train: Input[Dataset],\n",
    "        X_test: Input[Dataset],\n",
    "        base_model: Output[Model],\n",
    "        X_train_scaled: Output[Dataset],\n",
    "        X_test_scaled: Output[Dataset],\n",
    "        scaler_artifact: Output[Artifact]\n",
    "    ):\n",
    "        import pandas as pd\n",
    "        import joblib as jb\n",
    "        from sklearn.preprocessing import RobustScaler\n",
    "        from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "        def prepare_base_model():\n",
    "            # Create base model\n",
    "            model = RandomForestClassifier(\n",
    "                n_estimators=500, \n",
    "                random_state=42,\n",
    "                criterion=\"entropy\",\n",
    "                max_depth=39,\n",
    "                max_features=\"log2\",\n",
    "                min_samples_leaf=2\n",
    "            )\n",
    "            \n",
    "            # Save base model\n",
    "            jb.dump(model, base_model.path)\n",
    "            print(f\"Base model saved to: {base_model.path}\")\n",
    "            \n",
    "            # Load training and test data\n",
    "            X_train_data = pd.read_csv(X_train.path)\n",
    "            X_test_data = pd.read_csv(X_test.path)\n",
    "            \n",
    "            # Scale data\n",
    "            scaler = RobustScaler()\n",
    "            X_train_scaled_data = scaler.fit_transform(X_train_data)\n",
    "            X_test_scaled_data = scaler.transform(X_test_data)\n",
    "            \n",
    "            # Save scaler\n",
    "            jb.dump(scaler, scaler_artifact.path)\n",
    "            print(f\"Scaler saved to: {scaler_artifact.path}\")\n",
    "            \n",
    "            # Convert back to DataFrames and save\n",
    "            X_train_scaled_df = pd.DataFrame(X_train_scaled_data, columns=X_train_data.columns)\n",
    "            X_test_scaled_df = pd.DataFrame(X_test_scaled_data, columns=X_test_data.columns)\n",
    "            \n",
    "            X_train_scaled_df.to_csv(X_train_scaled.path, index=False)\n",
    "            X_test_scaled_df.to_csv(X_test_scaled.path, index=False)\n",
    "            \n",
    "            print(\"Model preparation completed\")\n",
    "\n",
    "        prepare_base_model()\n",
    "\n",
    "    @dsl.component(\n",
    "        base_image='python:3.11.9',\n",
    "        packages_to_install=[\n",
    "            'pandas==2.0.3',\n",
    "            'numpy==1.24.3',\n",
    "            'scikit-learn==1.3.0',\n",
    "            'joblib==1.3.2'\n",
    "        ]\n",
    "    )\n",
    "    def model_training(\n",
    "        base_model: Input[Model],\n",
    "        X_train_scaled: Input[Dataset],\n",
    "        X_test_scaled: Input[Dataset],\n",
    "        y_train: Input[Dataset],\n",
    "        y_test: Input[Dataset],\n",
    "        trained_model: Output[Model]\n",
    "    ):\n",
    "        import pandas as pd\n",
    "        import joblib as jb\n",
    "        from sklearn.ensemble import RandomForestClassifier\n",
    "        from sklearn.metrics import accuracy_score\n",
    "        from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "        def train_model():\n",
    "            # Load model and data\n",
    "            model = jb.load(base_model.path)\n",
    "            X_train_data = pd.read_csv(X_train_scaled.path)\n",
    "            X_test_data = pd.read_csv(X_test_scaled.path)\n",
    "            y_train_data = pd.read_csv(y_train.path)['Churn'].astype('int32')\n",
    "            y_test_data = pd.read_csv(y_test.path)['Churn'].astype('int32')\n",
    "            \n",
    "            print(f\"Training data shape: {X_train_data.shape}\")\n",
    "            print(f\"Test data shape: {X_test_data.shape}\")\n",
    "            \n",
    "            # Initial training\n",
    "            model.fit(X_train_data, y_train_data)\n",
    "            prediction = model.predict(X_test_data)\n",
    "            accuracy = accuracy_score(y_test_data, prediction)\n",
    "            print(f\"Initial model accuracy: {accuracy:.4f}\")\n",
    "            \n",
    "            # Fine-tuning if accuracy is low\n",
    "            if accuracy < 0.85:\n",
    "                print(\"Triggering fine-tuning...\")\n",
    "                rf_params = {\n",
    "                    'n_estimators': [100, 200, 300, 500],\n",
    "                    'criterion': ['gini', 'entropy'],\n",
    "                    'max_depth': [None, 10, 20, 30],\n",
    "                    'min_samples_split': [2, 5, 10],\n",
    "                    'min_samples_leaf': [1, 2, 4],\n",
    "                    'max_features': ['sqrt', 'log2'],\n",
    "                    'bootstrap': [True, False]\n",
    "                }\n",
    "                \n",
    "                random_search = RandomizedSearchCV(\n",
    "                    model, rf_params, cv=5, n_jobs=-1, n_iter=10, \n",
    "                    random_state=42, scoring='accuracy'\n",
    "                )\n",
    "                random_search.fit(X_train_data, y_train_data)\n",
    "                \n",
    "                best_model = RandomForestClassifier(**random_search.best_params_, random_state=42)\n",
    "                print(f\"Best parameters: {random_search.best_params_}\")\n",
    "                print(f\"Best CV score: {random_search.best_score_:.4f}\")\n",
    "                \n",
    "                # Evaluate best model\n",
    "                best_prediction = best_model.predict(X_test_data)\n",
    "                best_accuracy = accuracy_score(y_test_data, best_prediction)\n",
    "                print(f\"Best model test accuracy: {best_accuracy:.4f}\")\n",
    "            else:\n",
    "                print(\"No fine-tuning needed!\")\n",
    "                best_model = model\n",
    "            \n",
    "            # Save trained model\n",
    "            jb.dump(best_model, trained_model.path)\n",
    "            print(f\"Trained model saved to: {trained_model.path}\")\n",
    "\n",
    "        train_model()\n",
    "\n",
    "    @dsl.component(\n",
    "        base_image='python:3.11.9',\n",
    "        packages_to_install=[\n",
    "            'pandas==2.0.3',\n",
    "            'numpy==1.24.3',\n",
    "            'scikit-learn==1.3.0',\n",
    "            'matplotlib==3.7.2'\n",
    "        ]\n",
    "    )\n",
    "    def model_evaluation(\n",
    "        trained_model: Input[Model],\n",
    "        X_test_scaled: Input[Dataset],\n",
    "        y_test: Input[Dataset],\n",
    "        metrics_output: Output[Metrics],\n",
    "        pr_curve: Output[Artifact],\n",
    "        roc_curve: Output[Artifact]\n",
    "    ):\n",
    "        import pandas as pd\n",
    "        import joblib as jb\n",
    "        import matplotlib.pyplot as plt\n",
    "        import json\n",
    "        from sklearn.metrics import (\n",
    "            accuracy_score, precision_score, recall_score, f1_score,\n",
    "            classification_report, roc_curve as roc_curve_func, auc,\n",
    "            precision_recall_curve, average_precision_score,\n",
    "            matthews_corrcoef, roc_auc_score\n",
    "        )\n",
    "\n",
    "        def evaluate_model():\n",
    "            # Load model and data\n",
    "            model = jb.load(trained_model.path)\n",
    "            X_test_data = pd.read_csv(X_test_scaled.path)\n",
    "            y_test_data = pd.read_csv(y_test.path)['Churn'].astype('int32')\n",
    "            \n",
    "            # Make predictions\n",
    "            y_pred = model.predict(X_test_data)\n",
    "            y_pred_prob = model.predict_proba(X_test_data)[:, 1]\n",
    "            \n",
    "            # Calculate metrics\n",
    "            accuracy = accuracy_score(y_test_data, y_pred)\n",
    "            precision = precision_score(y_test_data, y_pred, average='weighted')\n",
    "            recall = recall_score(y_test_data, y_pred, average='weighted')\n",
    "            f1 = f1_score(y_test_data, y_pred, average='weighted')\n",
    "            roc_auc = roc_auc_score(y_test_data, y_pred_prob)\n",
    "            mcc = matthews_corrcoef(y_test_data, y_pred)\n",
    "            avg_precision = average_precision_score(y_test_data, y_pred_prob)\n",
    "            \n",
    "            metrics = {\n",
    "                \"accuracy\": float(accuracy),\n",
    "                \"precision\": float(precision),\n",
    "                \"recall\": float(recall),\n",
    "                \"f1_score\": float(f1),\n",
    "                \"roc_auc\": float(roc_auc),\n",
    "                \"mcc\": float(mcc),\n",
    "                \"avg_precision\": float(avg_precision)\n",
    "            }\n",
    "            metrics['classification_report'] = classification_report(y_test_data, y_pred)\n",
    "            print(f\"Model Evaluation Results:\")\n",
    "            for metric, value in metrics.items():\n",
    "                print(f\"  {metric}: {value:.4f}\")\n",
    "            \n",
    "            # Save metrics\n",
    "            with open(metrics_output.path, \"w\") as f:\n",
    "                json.dump(metrics, f, indent=2)\n",
    "            \n",
    "            # Generate Precision-Recall curve\n",
    "            precision_vals, recall_vals, _ = precision_recall_curve(y_test_data, y_pred_prob)\n",
    "            \n",
    "            plt.figure(figsize=(8, 6))\n",
    "            plt.plot(recall_vals, precision_vals, color='purple', lw=2,\n",
    "                    label=f'PR curve (AP = {avg_precision:.3f})')\n",
    "            plt.xlabel('Recall')\n",
    "            plt.ylabel('Precision')\n",
    "            plt.title('Precision-Recall Curve')\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            plt.savefig(pr_curve.path)\n",
    "            plt.close()\n",
    "            \n",
    "            # Generate ROC curve\n",
    "            fpr, tpr, _ = roc_curve_func(y_test_data, y_pred_prob)\n",
    "            \n",
    "            plt.figure(figsize=(8, 6))\n",
    "            plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (AUC = {roc_auc:.3f})')\n",
    "            plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
    "            plt.xlim([0.0, 1.0])\n",
    "            plt.ylim([0.0, 1.05])\n",
    "            plt.xlabel('False Positive Rate')\n",
    "            plt.ylabel('True Positive Rate')\n",
    "            plt.title('ROC Curve')\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            plt.savefig(roc_curve.path)\n",
    "            plt.close()\n",
    "            \n",
    "            print(\"Model evaluation completed\")\n",
    "\n",
    "        evaluate_model()\n",
    "\n",
    "    # Create tasks\n",
    "    data_ingestion_task = data_ingestion()\n",
    "    \n",
    "\n",
    "    data_split_task = data_split(processed_data=data_ingestion_task.outputs['processed_data'])\n",
    "    \n",
    "    model_prep_task = prepare_model(\n",
    "        X_train=data_split_task.outputs['X_train'],\n",
    "        X_test=data_split_task.outputs['X_test']\n",
    "    )\n",
    "    \n",
    "    training_task = model_training(\n",
    "        base_model=model_prep_task.outputs['base_model'],\n",
    "        X_train_scaled=model_prep_task.outputs['X_train_scaled'],\n",
    "        X_test_scaled=model_prep_task.outputs['X_test_scaled'],\n",
    "        y_train=data_split_task.outputs['y_train'],\n",
    "        y_test=data_split_task.outputs['y_test']\n",
    "    )\n",
    "    \n",
    "    evaluation_task = model_evaluation(\n",
    "        trained_model=training_task.outputs['trained_model'],\n",
    "        X_test_scaled=model_prep_task.outputs['X_test_scaled'],\n",
    "        y_test=data_split_task.outputs['y_test']\n",
    "    )\n",
    "    data_split_task.after(data_ingestion_task)\n",
    "    model_prep_task.after(data_split_task)\n",
    "    training_task.after(model_prep_task)\n",
    "    evaluation_task.after(training_task)\n",
    "    \n",
    "    \n",
    "    \n",
    "def compile_pipeline():\n",
    "    \"\"\"Compile the Kubeflow pipeline to YAML\"\"\"\n",
    "    try:\n",
    "        print(\"Compiling Kubeflow pipeline with GCS support...\")\n",
    "        compiler_instance = compiler.Compiler()\n",
    "        pipeline_file = \"churn_pipeline_gcs.yaml\"\n",
    "        compiler_instance.compile(\n",
    "            pipeline_func=churn_prediction_pipeline,\n",
    "            package_path=pipeline_file\n",
    "        )\n",
    "        print(f\"Pipeline compiled successfully: {pipeline_file}\")\n",
    "        return True, pipeline_file\n",
    "    except Exception as e:\n",
    "        print(f\"Error compiling pipeline: {e}\")\n",
    "        return False, None\n",
    "\n",
    "def deploy_pipeline():\n",
    "    \"\"\"Deploy pipeline to Kubeflow with GCS data source\"\"\"\n",
    "    max_retries = 3\n",
    "    retry_delay = 5\n",
    "\n",
    "    success, pipeline_file = compile_pipeline()\n",
    "    if not success:\n",
    "        return False\n",
    "\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            print(f\"Deploying pipeline to Kubeflow (attempt {attempt + 1}/{max_retries})...\")\n",
    "\n",
    "            client = Client(host='http://localhost:8080')\n",
    "            \n",
    "            run_name = f\"churn-prediction-gcs-{int(time.time())}\"\n",
    "\n",
    "            try:\n",
    "                experiment = client.get_experiment(experiment_name=\"churn-prediction-gcs-experiments\")\n",
    "            except:\n",
    "                experiment = client.create_experiment(name=\"churn-prediction-gcs-experiments\")\n",
    "\n",
    "            # Submit pipeline run\n",
    "            run = client.create_run_from_pipeline_package(\n",
    "                pipeline_file=pipeline_file,\n",
    "                run_name=run_name,\n",
    "                experiment_name=\"churn-prediction-gcs-experiments\"\n",
    "            )\n",
    "\n",
    "            print(f\" Pipeline run created successfully: {run.run_id}\")\n",
    "            print(f\" Data source: gs://churn_data_version/input_raw.csv\")\n",
    "            print(f\" Monitor progress at: http://localhost:8080/#/runs/details/{run.run_id}\")\n",
    "            \n",
    "            return True\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error deploying pipeline (attempt {attempt + 1}): {e}\")\n",
    "            \n",
    "            if attempt < max_retries - 1:\n",
    "                print(f\"Retrying in {retry_delay} seconds...\")\n",
    "                time.sleep(retry_delay)\n",
    "                retry_delay *= 2\n",
    "            else:\n",
    "                print(\"All retry attempts failed\")\n",
    "                return False\n",
    "\n",
    "    return False\n",
    "\n",
    "def run_kubeflow_pipeline():\n",
    "    \"\"\"Main function to run the Kubeflow pipeline with GCS\"\"\"\n",
    "    print(\"=\" * 70)\n",
    "    print(\"STARTING KUBEFLOW PIPELINE WITH GOOGLE CLOUD STORAGE\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    if not deploy_pipeline():\n",
    "        print(\"Pipeline deployment failed. Exiting.\")\n",
    "        return False\n",
    "    \n",
    "    print(\"=\" * 70)\n",
    "    print(\"KUBEFLOW PIPELINE DEPLOYMENT COMPLETED\")\n",
    "    print(\"Check Kubeflow UI at http://localhost:8080 for execution status\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    return True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "STARTING KUBEFLOW PIPELINE WITH GOOGLE CLOUD STORAGE\n",
      "======================================================================\n",
      "Compiling Kubeflow pipeline with GCS support...\n",
      "Pipeline compiled successfully: churn_pipeline_gcs.yaml\n",
      "Deploying pipeline to Kubeflow (attempt 1/3)...\n",
      "Error deploying pipeline (attempt 1): (504)\n",
      "Reason: Gateway Timeout\n",
      "HTTP response headers: HTTPHeaderDict({'X-Powered-By': 'Express', 'Date': 'Thu, 05 Jun 2025 08:44:29 GMT', 'Connection': 'keep-alive', 'Keep-Alive': 'timeout=5', 'Transfer-Encoding': 'chunked'})\n",
      "HTTP response body: Error occured while trying to proxy to: localhost:8080/apis/v2beta1/experiments?filter=%7B%22predicates%22%3A+%5B%7B%22operation%22%3A+1%2C+%22key%22%3A+%22display_name%22%2C+%22stringValue%22%3A+%22churn-prediction-gcs-experiments%22%7D%5D%7D&namespace=\n",
      "\n",
      "Retrying in 5 seconds...\n",
      "Deploying pipeline to Kubeflow (attempt 2/3)...\n",
      "Error deploying pipeline (attempt 2): (504)\n",
      "Reason: Gateway Timeout\n",
      "HTTP response headers: HTTPHeaderDict({'X-Powered-By': 'Express', 'Date': 'Thu, 05 Jun 2025 08:44:51 GMT', 'Connection': 'keep-alive', 'Keep-Alive': 'timeout=5', 'Transfer-Encoding': 'chunked'})\n",
      "HTTP response body: Error occured while trying to proxy to: localhost:8080/apis/v2beta1/experiments?filter=%7B%22predicates%22%3A+%5B%7B%22operation%22%3A+1%2C+%22key%22%3A+%22display_name%22%2C+%22stringValue%22%3A+%22churn-prediction-gcs-experiments%22%7D%5D%7D&namespace=\n",
      "\n",
      "Retrying in 10 seconds...\n",
      "Deploying pipeline to Kubeflow (attempt 3/3)...\n",
      "Error deploying pipeline (attempt 3): (504)\n",
      "Reason: Gateway Timeout\n",
      "HTTP response headers: HTTPHeaderDict({'X-Powered-By': 'Express', 'Date': 'Thu, 05 Jun 2025 08:45:01 GMT', 'Connection': 'keep-alive', 'Keep-Alive': 'timeout=5', 'Transfer-Encoding': 'chunked'})\n",
      "HTTP response body: Error occured while trying to proxy to: localhost:8080/apis/v2beta1/experiments?filter=%7B%22predicates%22%3A+%5B%7B%22operation%22%3A+1%2C+%22key%22%3A+%22display_name%22%2C+%22stringValue%22%3A+%22churn-prediction-gcs-experiments%22%7D%5D%7D&namespace=\n",
      "\n",
      "All retry attempts failed\n",
      "Pipeline deployment failed. Exiting.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_kubeflow_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\Desktop\\Data projects\\python\\Decision-making-system\\myenv\\Lib\\site-packages\\mlflow\\utils\\requirements_utils.py:12: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
